---
title: "Final Data Science Field"
author: "Andrew Le"
date: "2024-04-30"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Libraries in use

```{r library, message=FALSE, warning=FALSE}
library(tidyverse)
library(lubridate)
library(ggplot2)
library(dplyr)
```

### Purpose

This is Part 2 of the Data Science as a Field Final. We will be analyzing the mortality rates that were prevalant in California to see which county is the highest and which were the lowest. The reason why I want to look at this is because I myself am from California and I want to gain a more statistical perspective of the time that I lived in.

## First thing we will do is set up the data we are getting from the John Hopkins Github for COVID data

``` {r get_jhu_data}

urls <- c("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv",
          "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv",
          "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv",
          "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv")


```

## Now we will read in the data into respective values

```{r, import_data, message=FALSE}

global_cases <- read_csv(urls[1])
global_deaths <- read_csv(urls[2])
US_cases <- read_csv(urls[3])
US_deaths <- read_csv(urls[4])

```


## Now let's tidy up our data. We are going to tidy up both global cases and global deaths. While we are tidying global, we also might as well tidy up the USA cases and deaths as well.

```{r tidy_data}
global_cases <- global_cases %>%
  pivot_longer(cols =
                 -c('Province/State',
                    'Country/Region', Lat, Long),
               names_to = "date",
               values_to = "cases")

global_deaths <- global_deaths %>%
  pivot_longer(cols =
                 -c('Province/State',
                    'Country/Region', Lat, Long),
               names_to = "date",
               values_to = "deaths")

global <- global_cases %>%
  full_join(global_deaths) %>%
  rename(Country_Region = 'Country/Region',
         Province_State = 'Province/State') %>%
  mutate(date = mdy(date))

US_cases <- US_cases %>%
  pivot_longer(cols = -(UID:Combined_Key),
               names_to = "date",
               values_to = "cases")  %>%
  select(Admin2:cases) %>%
  mutate(date = mdy(date)) %>%
  select (-c(Lat, Long_))

US_deaths <- US_deaths %>%
  pivot_longer(cols = -(UID:Population),
               names_to = "date",
               values_to = "deaths")  %>%
  select(Admin2:deaths) %>%
  mutate(date = mdy(date)) %>%
  select (-c(Lat, Long_))

US <- US_cases %>%
  full_join(US_deaths)
```

## Summary of Global and USA Data

```{r summary}
summary(global)
summary(US)
```

## Now we are going to analyze the data and visualize. For our specific case, as we mentioned before, we want to look at counties in California only!

```{r visuals} 

california <- US %>%
  filter(Province_State == "California", cases > 0) %>%
  group_by(date, Admin2)

california_counties <- california %>%
  group_by(Admin2, date) %>%
  mutate(mortality_rate = deaths / cases) %>%
  select(Admin2, date, cases, deaths, Population, mortality_rate)

# Sum all California county cases, deaths, and populations.
california_totals <- california %>%
  group_by(date) %>%
  summarize(cases = sum(cases), deaths = sum(deaths), Population = sum(Population)) %>%
  select(date, cases, deaths, Population) %>%
  ungroup()

counties <- california_counties %>% 
  filter(date == "2024-04-30") %>%
  group_by(Admin2) %>%
  mutate(county_mortality_rate = deaths / cases) %>%
  select(date, Admin2, cases, deaths, Population, county_mortality_rate) %>%
  ungroup()

```

```{r results}
# total cali cases right now
max(california_totals$cases)

# total cali deaths right now
max(california_totals$deaths)

# cali mortality rate
max(california_totals$deaths) / max(california_totals$cases)

```

## Now we will finish off by creating a linear model to attempt to predict COVID test cases

``` {r modelll}
california_county_totals <- california_counties %>%
  group_by(Admin2) %>%
  summarize(deaths = max(deaths), cases = max(cases), Population = max(Population)) %>%
  mutate(cases_per_hundred = 100 * cases / Population, deaths_per_hundred = 100 * deaths / Population ) %>%
  select(Admin2, cases, deaths, Population, cases_per_hundred, deaths_per_hundred)

california_county_totals$cases_per_hundred[is.infinite(california_county_totals$cases_per_hundred)] <- NA
california_county_totals$deaths_per_hundred[is.infinite(california_county_totals$deaths_per_hundred)] <- NA

lr_model <- lm(deaths_per_hundred ~ cases_per_hundred, data = california_county_totals)

summary(lr_model)
```

##Conclusion

The county with the lowest rate is Almeda and the highest is Tehama. I also learned that although I can create this model above to "predict" the rate of COVID mortality, it is important to contextualize above because this kind of insight is not linear. We must be aware of biases as there is certaintly false or no-reports that change and mould the data to present a non-accurate conclusion.